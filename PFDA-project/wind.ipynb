{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Ideas\n",
    "\n",
    "\n",
    "suggested project: analyze wind speed around the country with a view to a wind farm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Plan\n",
    "\n",
    "__Research wind farms in Ireland__\n",
    "\n",
    "- where are they usually located?\n",
    "- what wind conditions do they need? any other site considerations? Rural locations.\n",
    "- how much electricity do they generate? summer vs winter?\n",
    "- cost?\n",
    "- lifespan?\n",
    "- advantages\n",
    "- disadvantages\n",
    "- anything else?\n",
    "\n",
    "__Project questions__\n",
    "\n",
    "What's the relationship between wind speed and power generated? Does the wind direction affect power generation? \n",
    "\n",
    "Is there a trend in wind speed? Is Ireland getting winder? Variations across the year? Time of day?\n",
    "\n",
    "Is the technology in wind turbines improving? Is more electricity being generated for the same wind speed?\n",
    "\n",
    "Does rain/temperature/anything affect the output? \n",
    "\n",
    "What happens during a storm? Does amount of wind generated electricity decrease/increase? \n",
    "\n",
    "Predict power output for wind farms in Ireland for the next week. Tricky\n",
    "\n",
    "As I have weather information could solar power to fill the gaps when wind speeds are low? Probably too big a task for this project. \n",
    "\n",
    "\n",
    "__Find data__\n",
    "\n",
    "Weather data from met Ã‰ireann historical data.\n",
    "    can select by site, perhaps initially analyse data for a number of weather stations near a wind farm and also weather stations not near a wind farm. From the data can I see why that site was selected?\n",
    "\n",
    "\n",
    "\n",
    "Is there much variation in wind across the country? Eirgrid data for entire country. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Background information\n",
    "\n",
    "https://windenergyireland.com/about-wind/the-basics/facts-stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "About the data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organising and Cleaning the Data\n",
    "\n",
    "\n",
    "Would be convenient to have all the data in one large data set. Need to research working with large data sets. More difficult to load than smaller data sets.\n",
    "\n",
    "Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind electricity data\n",
    "\n",
    "https://www.smartgriddashboard.com/#all\n",
    "\n",
    "[Eirgrid real-time system information](https://www.eirgrid.ie/grid/real-time-system-information) . On the Eirgrid website it is only possible to view information for one day at a time and up to one month ago. Despite extensive searching I couldn't find an official source of Eirgrid histprical data. I did find a [GitHub repository by Daniel Parke](https://github.com/Daniel-Parke/EirGrid_Data_Download/tree/main), who has written a very helpful python file to download all the historical data. His GitHub repository contains raw csv files for actual amount of electricity generated, actual demand, actual amount of electricity produced by wind for every year from 2014 for all Ireland, Northern Ireland and Republic of Ireland. I will need to run his program to get the most up to date data for 2024.\n",
    "\n",
    "As my weather data will be only for the Republic of Ireland, I am only interested in the csv files for the actual amount of electricity produced by wind for the Republic of Ireland. Each csv file containing one years worth of information was downloaded from the GitHub repository. After reading the data into pandas the next task will be to merge the files vertically using pd.concat(). Before I started on the onerous task of loading and concatenating each file separately, I came across a blog post on how to [read multiple csv file into pandas](https://saturncloud.io/blog/how-to-read-multiple-csv-files-into-python-pandas-dataframe). \n",
    "\n",
    "The solution to reading multiple files into pandas uses the glob module. Glob is a built-in module used to retrieve files/pathnames matching a specified pattern. It uses * wild cards to make path retrieval more simple and convenient. https://www.geeksforgeeks.org/how-to-use-glob-function-to-find-files-recursively-in-python/. [Real python](https://realpython.com/get-all-files-in-directory-python/#conditional-listing-using-glob) states that glob.glob() returns a list of filenames that match a pattern, which in this case are csv files. \n",
    "\n",
    "```python\n",
    "# Search for all csv files in the current working directory\n",
    "import glob\n",
    "glob.glob('*.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eirgrid have data on actual wind generation and the forecast wind generation. Could getting forecast information be of interest? Might help with machine learning. Github repository only contains actual data not forecast data. \n",
    "\n",
    "set up a scheduled task to download the data at midnight?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This was the first step to create a single dataframe from multiple csv files. \n",
    "## \n",
    "## Load the wind electricity files\n",
    "#\n",
    "## Find all csv files in the data/electricity directory\n",
    "#csv_files = glob.glob('data/electricity/*.csv')\n",
    "#\n",
    "## Create an empty dataframe to store the combined data\n",
    "#electricity_df = pd.DataFrame()\n",
    "#\n",
    "## Loop through each CSV file and append its contents to the combined dataframe\n",
    "#for csv_file in csv_files:\n",
    "#    df = pd.read_csv(csv_file, \n",
    "#                     header = None, \n",
    "#                     names = ['date', 'wind_actual', 'location', 'wind_value'], \n",
    "#                     index_col= 'date',\n",
    "#                     parse_dates= ['date'],\n",
    "#                     usecols= ['date', 'wind_value'])\n",
    "#    electricity_df = pd.concat([electricity_df, df])\n",
    "#\n",
    "#electricity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "electricity_df.info()\n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "DatetimeIndex: 361152 entries, 2021-01-01 00:00:00 to 2020-01-01 21:45:00\n",
    "Data columns (total 1 columns):\n",
    " #   Column      Non-Null Count   Dtype  \n",
    "---  ------      --------------   -----  \n",
    " 0   wind_value  361004 non-null  float64\n",
    "dtypes: float64(1)\n",
    "memory usage: 5.5 MB\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have a lot of duplicated rows. csv files have data for the 1st jan for the following year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#electricity_df.index.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/13035764/remove-pandas-rows-with-duplicate-indices\n",
    "#\n",
    "#electricity_df = electricity_df[~electricity_df.index.duplicated(keep= 'first')]\n",
    "#electricity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#electricity_df = electricity_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#electricity_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#electricity_df.to_csv('data/electricity/electricity_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_electricity_df = electricity_df.resample('h').mean()\n",
    "hourly_electricity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_electricity_df.to_csv('data/electricity/hourly_electricity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_electricity_df = pd.read_csv('data/electricity/merged_data/hourly_electricity.csv')\n",
    "hourly_electricity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data\n",
    "\n",
    "The weather data was downloaded from historic met eireann sites. Data from a range of weather stations was downloaded. The selected weather stations were mostly based on their proximity to a wind farm. A number were selected for the size of the data set. To see if Ireland is getting windier. Oldest weather stations with data are Dublin airport and Valentia who have data from 1 Jan 1944. \n",
    "\n",
    "Met Eireann weather data is recorded hourly. Electricity data recorded every 15min - resample to 1 hour. Saved resampled data to hourly_electricity.csv Should I read in this single csv file? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather Data\n",
    "\n",
    "What I'm aiming to do\n",
    "\n",
    "Look at wind speeds for the entire country. Is there much variability? Electricity generation values for the entire country. \n",
    "\n",
    "    Read all the csv files in weather directory into pandas.\n",
    "\n",
    "        Problems: some csv files have a different numbers of rows to skip. Function to remove the unnecessary rows from csv file. \n",
    "\n",
    "        The dataframe would ideally be the location. This is proving very difficult. Have written a function to extract the location from file name. \n",
    "\n",
    "    Refine the dataframe to the years 2014 onwards. Write a function. \n",
    "\n",
    "    Merge the dataframes\n",
    "        Can all the merging be done in one step? Write a function. \n",
    "\n",
    "Analyse the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there much variation in wind speed across the country? \n",
    "\n",
    "Electricity generated is given for ROI not broken down by wind farm.\n",
    "\n",
    "Electricity data from 2014, so to compare wind speed and amount of electricity generated by wind only need weather data from 2014. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to read in the weather data. Basic elements are the same skip rows, na_values, use columns, parse_dates\n",
    "\n",
    "What columns are needed? \n",
    "date, rain, temp, msl, wdsp, wddir, \n",
    "\n",
    "sun, clht, clamt not recorded for all weather stations. so not of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove explanatory rows in csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_rows(csv_file):\n",
    "    # Read the file, skipping metadata rows\n",
    "    with open(csv_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Identify the start of the data (row where actual CSV content begins)\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.lower().startswith('date,'):\n",
    "            data_start_idx = i\n",
    "    \n",
    "    return data_start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_rows('data/weather/hly275MaceHead.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_rows('data/weather/hly518ShannonAirport.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location(file_name):\n",
    "    '''A function to extract the location from the file name'''\n",
    "\n",
    "    pattern = r'hly\\d{3,4}([A-Z][a-z]+[A-Z]?[a-z]+).csv'\n",
    "\n",
    "    match = re.findall(pattern, file_name)\n",
    "\n",
    "    if match:\n",
    "        return match[0].lower()\n",
    "    else:\n",
    "        raise ValueError('File name does not match the expected pattern')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['johnstown', 'mullingar', 'dublinairport', 'athenry', 'gurteen', 'shannonairport', 'macehead', 'finner', 'corkairport', 'valentia', 'belmullet']\n"
     ]
    }
   ],
   "source": [
    "# Extract the location from the csv files in weather\n",
    "csv_files = glob.glob('data/weather/*.csv')\n",
    "\n",
    "location = []\n",
    "\n",
    "for file in csv_files:\n",
    "    name = extract_location(file)\n",
    "    location.append(name)\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                     rain  temp     msl  wdsp  wddir\n",
      "date                                                \n",
      "2003-08-12 01:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "2003-08-12 02:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "2003-08-12 03:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "2003-08-12 04:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "2003-08-12 05:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "...                   ...   ...     ...   ...    ...\n",
      "2024-10-31 20:00:00   0.0  11.6  1025.4   5.0  260.0\n",
      "2024-10-31 21:00:00   0.0  11.5  1025.2   4.0  270.0\n",
      "2024-10-31 22:00:00   0.0  11.5  1025.1   3.0  270.0\n",
      "2024-10-31 23:00:00   0.0  11.5  1024.9   3.0  260.0\n",
      "2024-11-01 00:00:00   0.0  11.6  1024.7   4.0  270.0\n",
      "\n",
      "[186048 rows x 5 columns],                      rain  temp     msl  wdsp  wddir\n",
      "date                                                \n",
      "1973-11-07 01:00:00   0.0   5.0  1030.3   7.0  220.0\n",
      "1973-11-07 02:00:00   0.0   5.3  1029.8   7.0  220.0\n",
      "1973-11-07 03:00:00   0.0   6.0  1029.3   9.0  230.0\n",
      "1973-11-07 04:00:00   0.0   6.1  1028.8   9.0  230.0\n",
      "1973-11-07 05:00:00   0.0   6.1  1028.1   9.0  220.0\n",
      "...                   ...   ...     ...   ...    ...\n",
      "2024-10-31 20:00:00   0.0   9.6  1024.8   5.0  220.0\n",
      "2024-10-31 21:00:00   0.0   9.4  1024.6   5.0  220.0\n",
      "2024-10-31 22:00:00   0.0   9.4  1024.5   5.0  230.0\n",
      "2024-10-31 23:00:00   0.0   9.4  1024.2   5.0  220.0\n",
      "2024-11-01 00:00:00   0.0   9.5  1023.8   5.0  220.0\n",
      "\n",
      "[446928 rows x 5 columns],                      rain  temp     msl  wdsp  wddir\n",
      "date                                                \n",
      "1944-01-01 00:00:00   0.0   7.2  1027.9    19  290.0\n",
      "1944-01-01 01:00:00   0.0   7.2  1027.6    19  280.0\n",
      "1944-01-01 02:00:00   0.0   7.2  1027.0    19  260.0\n",
      "1944-01-01 03:00:00   0.0   7.2  1026.2    19  270.0\n",
      "1944-01-01 04:00:00   0.0   7.2  1025.5    19  270.0\n",
      "...                   ...   ...     ...   ...    ...\n",
      "2024-10-31 20:00:00   0.0  10.5  1024.9     7  250.0\n",
      "2024-10-31 21:00:00   0.0  10.3  1024.7     7  250.0\n",
      "2024-10-31 22:00:00   0.0  10.2  1024.6     7  250.0\n",
      "2024-10-31 23:00:00   0.0  10.1  1024.3     6  240.0\n",
      "2024-11-01 00:00:00   0.0  10.3  1024.1     6  240.0\n",
      "\n",
      "[708601 rows x 5 columns],                      rain  temp     msl  wdsp  wddir\n",
      "date                                                \n",
      "2010-02-25 01:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "2010-02-25 02:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "2010-02-25 03:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "2010-02-25 04:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "2010-02-25 05:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "...                   ...   ...     ...   ...    ...\n",
      "2024-10-31 20:00:00   0.0  10.2  1024.6   4.0  200.0\n",
      "2024-10-31 21:00:00   0.0  10.3  1024.2   5.0  200.0\n",
      "2024-10-31 22:00:00   0.0  10.3  1024.2   5.0  210.0\n",
      "2024-10-31 23:00:00   0.0  10.5  1024.0   5.0  210.0\n",
      "2024-11-01 00:00:00   0.0  10.7  1023.5   5.0  210.0\n",
      "\n",
      "[128712 rows x 5 columns],                      rain  temp     msl  wdsp  wddir\n",
      "date                                                \n",
      "2007-12-31 01:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "2007-12-31 02:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "2007-12-31 03:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "2007-12-31 04:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "2007-12-31 05:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "...                   ...   ...     ...   ...    ...\n",
      "2024-10-31 20:00:00   0.0  10.0  1025.3   4.0  270.0\n",
      "2024-10-31 21:00:00   0.0  10.1  1024.9   4.0  270.0\n",
      "2024-10-31 22:00:00   0.0  10.0  1024.9   2.0  190.0\n",
      "2024-10-31 23:00:00   0.0  10.0  1024.8   3.0  190.0\n",
      "2024-11-01 00:00:00   0.0  10.0  1024.3   3.0  190.0\n",
      "\n",
      "[146928 rows x 5 columns],                      rain  temp     msl  wdsp  wddir\n",
      "date                                                \n",
      "1945-09-01 01:00:00   0.1  15.3  1011.6  17.0   90.0\n",
      "1945-09-01 02:00:00   0.0  15.0  1011.5  17.0   90.0\n",
      "1945-09-01 03:00:00   0.1  15.0  1011.3  17.0  100.0\n",
      "1945-09-01 04:00:00   0.0  15.0  1011.3  14.0   90.0\n",
      "1945-09-01 05:00:00   0.0  15.0  1011.3  16.0  110.0\n",
      "...                   ...   ...     ...   ...    ...\n",
      "2024-10-31 20:00:00   0.0  11.1  1025.3   2.0   10.0\n",
      "2024-10-31 21:00:00   0.0  11.2  1025.0   2.0   80.0\n",
      "2024-10-31 22:00:00   0.0  11.2  1025.1   2.0  130.0\n",
      "2024-10-31 23:00:00   0.0  11.2  1024.9   2.0  130.0\n",
      "2024-11-01 00:00:00   0.0  11.3  1024.4   3.0  150.0\n",
      "\n",
      "[693984 rows x 5 columns],                      rain  temp     msl  wdsp  wddir\n",
      "date                                                \n",
      "2003-08-13 01:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "2003-08-13 02:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "2003-08-13 03:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "2003-08-13 04:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "2003-08-13 05:00:00   NaN   NaN     NaN   NaN    NaN\n",
      "...                   ...   ...     ...   ...    ...\n",
      "2024-10-31 20:00:00   0.0  12.7  1024.0  11.0  240.0\n",
      "2024-10-31 21:00:00   0.0  12.8  1023.8  11.0  240.0\n",
      "2024-10-31 22:00:00   0.0  12.8  1023.6  11.0  240.0\n",
      "2024-10-31 23:00:00   0.0  12.7  1023.4  12.0  220.0\n",
      "2024-11-01 00:00:00   0.0  12.8  1023.1  13.0  230.0\n",
      "\n",
      "[186024 rows x 5 columns],                      rain  temp     msl  wdsp  wddir\n",
      "date                                                \n",
      "1997-05-29 17:00:00   NaN  21.1     NaN   NaN    NaN\n",
      "1997-05-29 18:00:00   NaN  21.1     NaN   NaN    NaN\n",
      "1997-05-29 19:00:00   NaN  19.7     NaN   NaN    NaN\n",
      "1997-05-29 20:00:00   NaN  18.9     NaN   NaN    NaN\n",
      "1997-05-29 23:00:00   NaN  12.1     NaN   NaN    NaN\n",
      "...                   ...   ...     ...   ...    ...\n",
      "2024-10-31 20:00:00   0.0  11.9  1023.1   6.0  240.0\n",
      "2024-10-31 21:00:00   0.0  11.8  1022.8   7.0  240.0\n",
      "2024-10-31 22:00:00   0.0  11.5  1022.5   4.0  240.0\n",
      "2024-10-31 23:00:00   0.0  11.1  1022.4   5.0  240.0\n",
      "2024-11-01 00:00:00   0.0  11.1  1022.2   5.0  210.0\n",
      "\n",
      "[232147 rows x 5 columns],                      rain  temp     msl  wdsp  wddir\n",
      "date                                                \n",
      "1962-01-01 01:00:00   NaN  -1.1  1016.0    14    340\n",
      "1962-01-01 02:00:00   NaN  -1.1  1016.5    10    340\n",
      "1962-01-01 03:00:00   NaN  -1.0  1016.7    12    320\n",
      "1962-01-01 04:00:00   NaN  -1.6  1017.2     8    330\n",
      "1962-01-01 05:00:00   NaN  -2.1  1018.0    11    320\n",
      "...                   ...   ...     ...   ...    ...\n",
      "2024-10-31 20:00:00   0.0  11.1  1025.5     2    220\n",
      "2024-10-31 21:00:00   0.0  10.9  1025.4     2    190\n",
      "2024-10-31 22:00:00   0.0  11.0  1025.2     2    180\n",
      "2024-10-31 23:00:00   0.0  11.1  1025.0     3    190\n",
      "2024-11-01 00:00:00   0.0  11.5  1024.6     2    250\n",
      "\n",
      "[550800 rows x 5 columns],                      rain  temp     msl  wdsp  wddir\n",
      "date                                                \n",
      "1944-01-01 00:00:00   0.0   9.3  1034.3  12.0  300.0\n",
      "1944-01-01 01:00:00   0.0   8.9  1033.9   9.0  290.0\n",
      "1944-01-01 02:00:00   0.0   9.4  1033.4  11.0  280.0\n",
      "1944-01-01 03:00:00   0.0   9.3  1032.8  11.0  280.0\n",
      "1944-01-01 04:00:00   0.5   8.6  1032.4  11.0  300.0\n",
      "...                   ...   ...     ...   ...    ...\n",
      "2024-10-31 20:00:00   0.0  12.3  1025.0   3.0  160.0\n",
      "2024-10-31 21:00:00   0.0  12.3  1024.5   3.0  160.0\n",
      "2024-10-31 22:00:00   0.0  12.2  1024.7   3.0  170.0\n",
      "2024-10-31 23:00:00   0.0  12.2  1024.4   3.0  160.0\n",
      "2024-11-01 00:00:00   0.0  11.9  1024.1   2.0  180.0\n",
      "\n",
      "[708600 rows x 5 columns],                      rain  temp     msl  wdsp  wddir\n",
      "date                                                \n",
      "1956-09-16 15:00:00   0.0  14.4  1026.7   0.0    0.0\n",
      "1956-09-16 16:00:00   0.0  13.9  1026.6   0.0    0.0\n",
      "1956-09-16 17:00:00   0.0  14.2  1026.4   0.0    0.0\n",
      "1956-09-16 18:00:00   0.0  13.0  1026.5   0.0    0.0\n",
      "1956-09-16 19:00:00   0.0  12.6  1026.8   0.0    0.0\n",
      "...                   ...   ...     ...   ...    ...\n",
      "2024-10-31 20:00:00   0.0  11.4  1023.1  12.0  210.0\n",
      "2024-10-31 21:00:00   0.0  11.7  1022.7  13.0  210.0\n",
      "2024-10-31 22:00:00   0.0  11.9  1022.3  14.0  210.0\n",
      "2024-10-31 23:00:00   0.0  12.1  1022.3  13.0  210.0\n",
      "2024-11-01 00:00:00   0.0  12.2  1022.4  16.0  210.0\n",
      "\n",
      "[597178 rows x 5 columns]]\n"
     ]
    }
   ],
   "source": [
    "csv_files = glob.glob('data/weather/*.csv')\n",
    "\n",
    "l = []\n",
    "\n",
    "for filename in csv_files:\n",
    "    for skip_rows in [17, 23]:\n",
    "        try:\n",
    "            df = pd.read_csv(filename, skiprows= skip_rows, na_values= ' ', usecols= ['date', 'rain', 'temp', 'msl', 'wdsp', 'wddir'], index_col= 'date', parse_dates= ['date'], date_format = \"%d-%b-%Y %H:%M\")\n",
    "            l.append(df)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.concat(l, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>msl</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wddir</th>\n",
       "      <th>rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>msl</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wddir</th>\n",
       "      <th>...</th>\n",
       "      <th>rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>msl</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wddir</th>\n",
       "      <th>rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>msl</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wddir</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1944-01-01 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1034.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944-01-01 01:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1033.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944-01-01 02:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1033.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944-01-01 03:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1032.8</td>\n",
       "      <td>11.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944-01-01 04:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1032.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rain  temp  msl  wdsp  wddir  rain  temp  msl  wdsp  \\\n",
       "date                                                                       \n",
       "1944-01-01 00:00:00   NaN   NaN  NaN   NaN    NaN   NaN   NaN  NaN   NaN   \n",
       "1944-01-01 01:00:00   NaN   NaN  NaN   NaN    NaN   NaN   NaN  NaN   NaN   \n",
       "1944-01-01 02:00:00   NaN   NaN  NaN   NaN    NaN   NaN   NaN  NaN   NaN   \n",
       "1944-01-01 03:00:00   NaN   NaN  NaN   NaN    NaN   NaN   NaN  NaN   NaN   \n",
       "1944-01-01 04:00:00   NaN   NaN  NaN   NaN    NaN   NaN   NaN  NaN   NaN   \n",
       "\n",
       "                     wddir  ...  rain  temp     msl  wdsp  wddir  rain  temp  \\\n",
       "date                        ...                                                \n",
       "1944-01-01 00:00:00    NaN  ...   0.0   9.3  1034.3  12.0  300.0   NaN   NaN   \n",
       "1944-01-01 01:00:00    NaN  ...   0.0   8.9  1033.9   9.0  290.0   NaN   NaN   \n",
       "1944-01-01 02:00:00    NaN  ...   0.0   9.4  1033.4  11.0  280.0   NaN   NaN   \n",
       "1944-01-01 03:00:00    NaN  ...   0.0   9.3  1032.8  11.0  280.0   NaN   NaN   \n",
       "1944-01-01 04:00:00    NaN  ...   0.5   8.6  1032.4  11.0  300.0   NaN   NaN   \n",
       "\n",
       "                     msl  wdsp  wddir  \n",
       "date                                   \n",
       "1944-01-01 00:00:00  NaN   NaN    NaN  \n",
       "1944-01-01 01:00:00  NaN   NaN    NaN  \n",
       "1944-01-01 02:00:00  NaN   NaN    NaN  \n",
       "1944-01-01 03:00:00  NaN   NaN    NaN  \n",
       "1944-01-01 04:00:00  NaN   NaN    NaN  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = weather_df['2014' :'2024']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>msl</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wddir</th>\n",
       "      <th>rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>msl</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wddir</th>\n",
       "      <th>...</th>\n",
       "      <th>rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>msl</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wddir</th>\n",
       "      <th>rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>msl</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wddir</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>992.4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>989.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>988.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>984.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>992.4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>989.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>987.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>983.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>991.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>989.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>986.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>983.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>991.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>988.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>984.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>982.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>989.6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>987.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>981.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>981.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rain  temp    msl  wdsp  wddir  rain  temp    msl  wdsp  \\\n",
       "date                                                                           \n",
       "2014-01-01 00:00:00   0.0   7.6  992.4  13.0  220.0   0.0   3.4  989.8   8.0   \n",
       "2014-01-01 01:00:00   0.0   6.6  992.4  11.0  230.0   0.0   3.0  989.7   7.0   \n",
       "2014-01-01 02:00:00   0.0   6.7  991.7   9.0  210.0   0.0   3.0  989.1   7.0   \n",
       "2014-01-01 03:00:00   0.0   7.5  991.1  10.0  210.0   0.1   3.0  988.5   7.0   \n",
       "2014-01-01 04:00:00   0.0   8.0  989.6  11.0  200.0   0.0   2.8  987.4   7.0   \n",
       "\n",
       "                     wddir  ...  rain  temp    msl  wdsp  wddir  rain  temp  \\\n",
       "date                        ...                                               \n",
       "2014-01-01 00:00:00  180.0  ...   0.0   7.5  988.7   9.0  180.0   0.0   7.1   \n",
       "2014-01-01 01:00:00  180.0  ...   0.0   7.2  987.5   7.0  180.0   0.0   6.4   \n",
       "2014-01-01 02:00:00  180.0  ...   0.3   8.4  986.2   9.0  180.0   0.1   7.2   \n",
       "2014-01-01 03:00:00  170.0  ...   1.6   7.1  984.4   9.0  180.0   0.1   7.0   \n",
       "2014-01-01 04:00:00  160.0  ...   0.8   7.7  981.9   8.0  160.0   1.0   6.6   \n",
       "\n",
       "                       msl  wdsp  wddir  \n",
       "date                                     \n",
       "2014-01-01 00:00:00  984.0  17.0  210.0  \n",
       "2014-01-01 01:00:00  983.7  17.0  200.0  \n",
       "2014-01-01 02:00:00  983.2  15.0  200.0  \n",
       "2014-01-01 03:00:00  982.5  16.0  190.0  \n",
       "2014-01-01 04:00:00  981.6  16.0  190.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 94969 entries, 2014-01-01 00:00:00 to 2024-11-01 00:00:00\n",
      "Freq: h\n",
      "Data columns (total 55 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   rain    94940 non-null  float64\n",
      " 1   temp    94941 non-null  float64\n",
      " 2   msl     94941 non-null  float64\n",
      " 3   wdsp    94935 non-null  float64\n",
      " 4   wddir   94939 non-null  float64\n",
      " 5   rain    94959 non-null  float64\n",
      " 6   temp    94961 non-null  float64\n",
      " 7   msl     94961 non-null  float64\n",
      " 8   wdsp    94956 non-null  float64\n",
      " 9   wddir   94959 non-null  float64\n",
      " 10  rain    94969 non-null  float64\n",
      " 11  temp    94969 non-null  float64\n",
      " 12  msl     94969 non-null  float64\n",
      " 13  wdsp    94969 non-null  int64  \n",
      " 14  wddir   94969 non-null  float64\n",
      " 15  rain    94956 non-null  float64\n",
      " 16  temp    94957 non-null  float64\n",
      " 17  msl     94869 non-null  float64\n",
      " 18  wdsp    94943 non-null  float64\n",
      " 19  wddir   94943 non-null  float64\n",
      " 20  rain    94932 non-null  float64\n",
      " 21  temp    94941 non-null  float64\n",
      " 22  msl     94921 non-null  float64\n",
      " 23  wdsp    94934 non-null  float64\n",
      " 24  wddir   94946 non-null  float64\n",
      " 25  rain    94969 non-null  float64\n",
      " 26  temp    94969 non-null  float64\n",
      " 27  msl     94969 non-null  float64\n",
      " 28  wdsp    94958 non-null  float64\n",
      " 29  wddir   94958 non-null  float64\n",
      " 30  rain    94969 non-null  float64\n",
      " 31  temp    94969 non-null  float64\n",
      " 32  msl     94969 non-null  float64\n",
      " 33  wdsp    94969 non-null  float64\n",
      " 34  wddir   94968 non-null  float64\n",
      " 35  rain    94968 non-null  float64\n",
      " 36  temp    94969 non-null  float64\n",
      " 37  msl     94969 non-null  float64\n",
      " 38  wdsp    94969 non-null  float64\n",
      " 39  wddir   94969 non-null  float64\n",
      " 40  rain    94969 non-null  float64\n",
      " 41  temp    94969 non-null  float64\n",
      " 42  msl     94969 non-null  float64\n",
      " 43  wdsp    94969 non-null  float64\n",
      " 44  wddir   94969 non-null  float64\n",
      " 45  rain    94967 non-null  float64\n",
      " 46  temp    94969 non-null  float64\n",
      " 47  msl     94969 non-null  float64\n",
      " 48  wdsp    94925 non-null  float64\n",
      " 49  wddir   94860 non-null  float64\n",
      " 50  rain    94969 non-null  float64\n",
      " 51  temp    94969 non-null  float64\n",
      " 52  msl     94969 non-null  float64\n",
      " 53  wdsp    94969 non-null  float64\n",
      " 54  wddir   94969 non-null  float64\n",
      "dtypes: float64(54), int64(1)\n",
      "memory usage: 40.6 MB\n"
     ]
    }
   ],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/68233237/computing-row-average-of-columns-with-same-name-in-pandas\n",
    "weather_df_mean = weather_df.T.groupby(weather_df.columns).mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msl</th>\n",
       "      <th>rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>wddir</th>\n",
       "      <th>wdsp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01 00:00:00</th>\n",
       "      <td>988.718182</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>5.772727</td>\n",
       "      <td>190.909091</td>\n",
       "      <td>12.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 01:00:00</th>\n",
       "      <td>988.390909</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>5.281818</td>\n",
       "      <td>186.363636</td>\n",
       "      <td>10.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 02:00:00</th>\n",
       "      <td>987.736364</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>5.590909</td>\n",
       "      <td>176.363636</td>\n",
       "      <td>10.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 03:00:00</th>\n",
       "      <td>986.854545</td>\n",
       "      <td>0.209091</td>\n",
       "      <td>5.472727</td>\n",
       "      <td>171.818182</td>\n",
       "      <td>10.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 04:00:00</th>\n",
       "      <td>985.463636</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5.590909</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>10.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-31 20:00:00</th>\n",
       "      <td>1024.636364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.127273</td>\n",
       "      <td>207.272727</td>\n",
       "      <td>5.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-31 21:00:00</th>\n",
       "      <td>1024.345455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.118182</td>\n",
       "      <td>211.818182</td>\n",
       "      <td>5.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-31 22:00:00</th>\n",
       "      <td>1024.245455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.090909</td>\n",
       "      <td>210.909091</td>\n",
       "      <td>5.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-31 23:00:00</th>\n",
       "      <td>1024.054545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.081818</td>\n",
       "      <td>206.363636</td>\n",
       "      <td>5.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-01 00:00:00</th>\n",
       "      <td>1023.745455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.172727</td>\n",
       "      <td>214.545455</td>\n",
       "      <td>5.818182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94969 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             msl      rain       temp       wddir       wdsp\n",
       "date                                                                        \n",
       "2014-01-01 00:00:00   988.718182  0.036364   5.772727  190.909091  12.363636\n",
       "2014-01-01 01:00:00   988.390909  0.027273   5.281818  186.363636  10.909091\n",
       "2014-01-01 02:00:00   987.736364  0.036364   5.590909  176.363636  10.545455\n",
       "2014-01-01 03:00:00   986.854545  0.209091   5.472727  171.818182  10.181818\n",
       "2014-01-01 04:00:00   985.463636  0.200000   5.590909  160.000000  10.545455\n",
       "...                          ...       ...        ...         ...        ...\n",
       "2024-10-31 20:00:00  1024.636364  0.000000  11.127273  207.272727   5.545455\n",
       "2024-10-31 21:00:00  1024.345455  0.000000  11.118182  211.818182   5.727273\n",
       "2024-10-31 22:00:00  1024.245455  0.000000  11.090909  210.909091   5.272727\n",
       "2024-10-31 23:00:00  1024.054545  0.000000  11.081818  206.363636   5.454545\n",
       "2024-11-01 00:00:00  1023.745455  0.000000  11.172727  214.545455   5.818182\n",
       "\n",
       "[94969 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_mean.to_csv('data/weather/merged_data/weather_mean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the location from the csv files in weather\n",
    "csv_files = glob.glob('data/weather/*.csv')\n",
    "\n",
    "location_dict = {}\n",
    "\n",
    "for file in csv_files:\n",
    "    name = extract_location(file)\n",
    "    location_dict[name + '_df'] = file\n",
    "print(location_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weather(file_name):\n",
    "    '''A function to read in a weather csv file.'''\n",
    "       \n",
    "    file_path = 'data/weather/'\n",
    "\n",
    "    for skip_rows in [17, 23]:\n",
    "        weather_df = pd.read_csv(file_path + file_name,\n",
    "            skiprows = skip_rows,\n",
    "            usecols= ['date', 'rain', 'temp', 'msl', 'wdsp', 'wddir'],\n",
    "            na_values = ' ',\n",
    "            index_col= 'date', \n",
    "            parse_dates= ['date'], \n",
    "            date_format = \"%d-%b-%Y %H:%M\")\n",
    "            \n",
    "        weather_df = weather_df['2014': '2024']\n",
    "\n",
    "    return weather_df\n",
    "\n",
    "#date, rain,temp,msl,wdsp,wddir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_filter_csv(file_path):\n",
    "\n",
    "    file_path = 'data/weather/'\n",
    "\n",
    "    for skip_rows in [17, 23]:  # Try skipping 17 or 23 rows\n",
    "        try:\n",
    "            df = pd.read_csv(file_path + file_path, skiprows=skip_rows)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            continue  # Try the next skiprows value if an error occurs\n",
    "    \n",
    "    # Return an empty DataFrame if neither option works\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gurteen = load_weather('hly1475Gurteen.csv')\n",
    "gurteen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macehead = load_weather('hly275MaceHead.csv')\n",
    "macehead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mullingar = load_weather('hly875Mullingar.csv', 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "johnstown = load_weather('hly1775Johnstown.csv', 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "athenry = load_weather('hly1875Athenry.csv', 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finner = load_weather('hly2075Finner.csv', 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refine dataframes to 2014 data onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_years(df):\n",
    "    df = df['2014': '2024']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice merging dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gurteen_macehead = gurteen.merge(macehead, on= 'date', suffixes= ['_gur', '_mace'])\n",
    "gurteen_macehead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = extract_location('hly275MaceHead.csv')\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = extract_location('hly1475Gurteen.csv')\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gurteen = load_weather('hly1475Gurteen.csv', 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regex the filename\n",
    " # Want df to have the station name in the name of the df\n",
    " #pattern = r'hly\\d{3,4}([A-Z][a-z]+).csv'\n",
    " #my_string = file_name\n",
    " #match = re.search(pattern, my_string)\n",
    " #name = match.group(1).lower()\n",
    " #name_df = f\"{name}_df\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(name_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to the file name to name the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df = name('hly275MaceHead.csv')\n",
    "\n",
    "df_name('hly875Mullingar.csv', 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mullingar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name('hly875Mullingar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame with name extracted from the csv file\n",
    "name_df = name('hly875Mullingar.csv')\n",
    "\n",
    "name_df = load_weather('hly875Mullingar.csv', 17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df = name('hly2375Belmullet.csv')\n",
    "name_df = load_weather('hly2375Belmullet.csv', 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belmullet_df = pd.read_csv('data/weather/hly2375Belmullet.csv', \n",
    "                           skiprows = 23,\n",
    "                           usecols= ['date', 'rain', 'temp', 'msl', 'wdsp', 'wddir'],\n",
    "                           na_values = ' ',\n",
    "                           index_col= 'date', \n",
    "                           parse_dates= ['date'], \n",
    "                           date_format = \"%d-%b-%Y %H:%M\")\n",
    "\n",
    "belmullet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows from 2014\n",
    "\n",
    "belmullet_df = belmullet_df.loc['2014' : '2024']\n",
    "\n",
    "belmullet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge weather dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Is Ireland getting windier? Use Dublin Airport data. Recorded from 1944. Also Valentia recorded from then too. Do Dublin first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dublin_df = pd.read_csv('data/weather/hly532DublinAirport.csv', \n",
    "                        skiprows = 23, \n",
    "                        na_values = ' ',\n",
    "                        index_col= 'date', \n",
    "                        parse_dates= ['date'], \n",
    "                        date_format = \"%d-%b-%Y %H:%M\")\n",
    "\n",
    "dublin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dublin_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dublin_df = dublin_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dublin_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dublin_monthly = dublin_df.resample('ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "\n",
    "dublin_yearly = dublin_df.resample('YE')\n",
    "\n",
    "\n",
    "dublin_df['wdsp'].resample('YE').mean().scatterplot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dublin_yearly['wdsp'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 11, 9\n",
    "\n",
    "decomposition = sm.tsa.seasonal_decompose(dublin_monthly['wdsp'].mean(), model= 'additive', period = 12)\n",
    "fig = decomposition.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose, STL , MSTL\n",
    "#from statsforecast import StatsForecast\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valentia_df = pd.read_csv('data/weather/hly2275Valentia.csv', \n",
    "                        skiprows = 23, \n",
    "                        na_values = ' ',\n",
    "                        index_col= 'date', \n",
    "                        parse_dates= ['date'], \n",
    "                        date_format = \"%d-%b-%Y %H:%M\")\n",
    "\n",
    "valentia_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "\n",
    "valentia_df['wdsp'].resample('YE').mean().plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valentia_monthly = valentia_df.resample('ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 11, 9\n",
    "\n",
    "decomposition = sm.tsa.seasonal_decompose(valentia_monthly['wdsp'].mean(), model= 'additive', period = 12)\n",
    "fig = decomposition.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very quick plot of electricity generation by year\n",
    "\n",
    "mean_wind_elect_year = electricity_df.resample('YE').mean()\n",
    "\n",
    "mean_wind_elect_year.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of the Analysis\n",
    "\n",
    "nice plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "some predictive analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\n",
    "http://www.iwea.ie/technicalfaqs\n",
    "\n",
    "\n",
    "### Data Sets\n",
    "\n",
    "[GitHub Daniel Parke]https://github.com/Daniel-Parke/EirGrid_Data_Download/tree/main\n",
    "\n",
    "\n",
    "__Problems that arose__\n",
    "\n",
    "[Git LFS (large file storage)](https://git-lfs.com/). Some of the weather data filew were larger than GitHub's recommended maximum file size of 50.00 MB. Installed and used Git lfs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
