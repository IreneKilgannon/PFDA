{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Ideas\n",
    "\n",
    "\n",
    "suggested project: analyse wind speed around the country with a view to a wind farm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Plan\n",
    "\n",
    "__Research wind farms in Ireland__\n",
    "\n",
    "- where are they usually located?\n",
    "- what wind conditions do they need? any other site considerations? Rural locations.\n",
    "- how much electricity do they generate? summer vs winter?\n",
    "- cost?\n",
    "- lifespan?\n",
    "- advantages\n",
    "- disadvantages\n",
    "- anything else?\n",
    "\n",
    "__Project questions__\n",
    "\n",
    "What's the relationship between wind speed and power generated? Does the wind direction affect power generation? \n",
    "\n",
    "Is there a trend in wind speed? Is Ireland getting winder? Variations across the year? Time of day?\n",
    "\n",
    "Is the technology in wind turbines improving? Is more electricity being generated for the same wind speed?\n",
    "\n",
    "Does rain/temperature/anything affect the output? \n",
    "\n",
    "What happens during a storm? Does amount of wind generated electricity decrease/increase? \n",
    "\n",
    "Predict power output for wind farms in Ireland for the next week. Tricky\n",
    "\n",
    "As I have weather information could solar power to fill the gaps when wind speeds are low? Probably too big a task for this project. \n",
    "\n",
    "\n",
    "__Find data__\n",
    "\n",
    "Weather data from met Ã‰ireann historical data.\n",
    "    can select by site, perhaps initially analyse data for a number of weather stations near a wind farm and also weather stations not near a wind farm. From the data can I see why that site was selected?\n",
    "\n",
    "\n",
    "\n",
    "Is there much variation in wind across the country? Eirgrid data for entire country. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Background information\n",
    "\n",
    "https://windenergyireland.com/about-wind/the-basics/facts-stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "About the data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organising and Cleaning the Data\n",
    "\n",
    "\n",
    "Would be convenient to have all the data in one large data set. Need to research working with large data sets. More difficult to load than smaller data sets.\n",
    "\n",
    "Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind electricity data\n",
    "\n",
    "https://www.smartgriddashboard.com/#all\n",
    "\n",
    "[Eirgrid real-time system information](https://www.eirgrid.ie/grid/real-time-system-information) . On the Eirgrid website it is only possible to view information for one day at a time and up to one month ago. Despite extensive searching I couldn't find an official source of Eirgrid histprical data. I did find a [GitHub repository by Daniel Parke](https://github.com/Daniel-Parke/EirGrid_Data_Download/tree/main), who has written a very helpful python file to download all the historical data. His GitHub repository contains raw csv files for actual amount of electricity generated, actual demand, actual amount of electricity produced by wind for every year from 2014 for all Ireland, Northern Ireland and Republic of Ireland. I will need to run his program to get the most up to date data for 2024.\n",
    "\n",
    "As my weather data will be only for the Republic of Ireland, I am only interested in the csv files for the actual amount of electricity produced by wind for the Republic of Ireland. Each csv file containing one years worth of information was downloaded from the GitHub repository. After reading the data into pandas the next task will be to merge the files vertically using pd.concat(). Before I started on the onerous task of loading and concatenating each file separately, I came across a blog post on how to [read multiple csv file into pandas](https://saturncloud.io/blog/how-to-read-multiple-csv-files-into-python-pandas-dataframe). \n",
    "\n",
    "The solution to reading multiple files into pandas uses the glob module. Glob is a built-in module used to retrieve files/pathnames matching a specified pattern. It uses * wild cards to make path retrieval more simple and convenient. https://www.geeksforgeeks.org/how-to-use-glob-function-to-find-files-recursively-in-python/. [Real python](https://realpython.com/get-all-files-in-directory-python/#conditional-listing-using-glob) states that glob.glob() returns a list of filenames that match a pattern, which in this case are csv files. \n",
    "\n",
    "```python\n",
    "# Search for all csv files in the current working directory\n",
    "import glob\n",
    "glob.glob('*.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eirgrid have data on actual wind generation and the forecast wind generation. Could getting forecast information be of interest? Might help with machine learning. Github repository only contains actual data not forecast data. \n",
    "\n",
    "set up a scheduled task to download the data at midnight?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This was the first step to create a single dataframe from multiple csv files. \n",
    "## \n",
    "## Load the wind electricity files\n",
    "#\n",
    "## Find all csv files in the data/electricity directory\n",
    "#csv_files = glob.glob('data/electricity/*.csv')\n",
    "#\n",
    "## Create an empty dataframe to store the combined data\n",
    "#electricity_df = pd.DataFrame()\n",
    "#\n",
    "## Loop through each CSV file and append its contents to the combined dataframe\n",
    "#for csv_file in csv_files:\n",
    "#    df = pd.read_csv(csv_file, \n",
    "#                     header = None, \n",
    "#                     names = ['date', 'wind_actual', 'location', 'wind_value'], \n",
    "#                     index_col= 'date',\n",
    "#                     parse_dates= ['date'],\n",
    "#                     usecols= ['date', 'wind_value'])\n",
    "#    electricity_df = pd.concat([electricity_df, df])\n",
    "#\n",
    "#electricity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "electricity_df.info()\n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "DatetimeIndex: 361152 entries, 2021-01-01 00:00:00 to 2020-01-01 21:45:00\n",
    "Data columns (total 1 columns):\n",
    " #   Column      Non-Null Count   Dtype  \n",
    "---  ------      --------------   -----  \n",
    " 0   wind_value  361004 non-null  float64\n",
    "dtypes: float64(1)\n",
    "memory usage: 5.5 MB\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have a lot of duplicated rows. csv files have data for the 1st jan for the following year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#electricity_df.index.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/13035764/remove-pandas-rows-with-duplicate-indices\n",
    "#\n",
    "#electricity_df = electricity_df[~electricity_df.index.duplicated(keep= 'first')]\n",
    "#electricity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#electricity_df = electricity_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#electricity_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#electricity_df.to_csv('data/electricity/electricity_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_electricity_df = electricity_df.resample('h').mean()\n",
    "hourly_electricity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_electricity_df.to_csv('data/electricity/hourly_electricity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_electricity_df = pd.read_csv('data/electricity/merged_data/hourly_electricity.csv')\n",
    "hourly_electricity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data\n",
    "\n",
    "The weather data was downloaded from historic met eireann sites. Data from a range of weather stations was downloaded. The selected weather stations were mostly based on their proximity to a wind farm. A number were selected for the size of the data set. To see if Ireland is getting windier. Oldest weather stations with data are Dublin airport and Valentia who have data from 1 Jan 1944. \n",
    "\n",
    "Met Eireann weather data is recorded hourly. Electricity data recorded every 15min - resample to 1 hour. Saved resampled data to hourly_electricity.csv Should I read in this single csv file? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather Data\n",
    "\n",
    "What I'm aiming to do\n",
    "\n",
    "Look at wind speeds for the entire country. Is there much variability? Electricity generation values for the entire country. \n",
    "\n",
    "    Read all the csv files in weather directory into pandas.\n",
    "\n",
    "        Problems: some csv files have a different numbers of rows to skip. Function to remove the unnecessary rows from csv file. \n",
    "\n",
    "        The dataframe would ideally be the location. This is proving very difficult. Have written a function to extract the location from file name. \n",
    "\n",
    "    Refine the dataframe to the years 2014 onwards. Write a function. \n",
    "\n",
    "    Merge the dataframes\n",
    "        Can all the merging be done in one step? Write a function. \n",
    "\n",
    "Analyse the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there much variation in wind speed across the country? \n",
    "\n",
    "Electricity generated is given for ROI not broken down by wind farm.\n",
    "\n",
    "Electricity data from 2014, so to compare wind speed and amount of electricity generated by wind only need weather data from 2014. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to read in the weather data. Basic elements are the same skip rows, na_values, use columns, parse_dates\n",
    "\n",
    "What columns are needed? \n",
    "date, rain, temp, msl, wdsp, wddir, \n",
    "\n",
    "sun, clht, clamt not recorded for all weather stations. so not of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove explanatory rows in csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_rows(csv_file):\n",
    "    # Read the file, skipping metadata rows\n",
    "    with open(csv_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Identify the start of the data (row where actual CSV content begins)\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.lower().startswith('date,'):\n",
    "            data_start_idx = i\n",
    "    \n",
    "    return data_start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_start_idx = skip_rows('data/weather/hly275MaceHead.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_rows('data/weather/hly275MaceHead.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_rows('data/weather/hly518ShannonAirport.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location(file_name):\n",
    "    '''A function to extract the location from the file name'''\n",
    "\n",
    "    pattern = r'hly\\d{3,4}([A-Z][a-z]+[A-Z]?[a-z]+).csv'\n",
    "\n",
    "    match = re.findall(pattern, file_name)\n",
    "\n",
    "    if match:\n",
    "        return match[0].lower()\n",
    "    else:\n",
    "        raise ValueError('File name does not match the expected pattern')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['johnstown', 'mullingar', 'athenry', 'gurteen', 'macehead', 'finner']\n"
     ]
    }
   ],
   "source": [
    "# Extract the location from the csv files in weather\n",
    "csv_files = glob.glob('data/weather/*.csv')\n",
    "\n",
    "location = []\n",
    "\n",
    "for file in csv_files:\n",
    "    name = extract_location(file)\n",
    "    location.append(name)\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'johnstown_df': 'data/weather/hly1775Johnstown.csv', 'mullingar_df': 'data/weather/hly875Mullingar.csv', 'athenry_df': 'data/weather/hly1875Athenry.csv', 'gurteen_df': 'data/weather/hly1475Gurteen.csv', 'macehead_df': 'data/weather/hly275MaceHead.csv', 'finner_df': 'data/weather/hly2075Finner.csv'}\n"
     ]
    }
   ],
   "source": [
    "# Extract the location from the csv files in weather\n",
    "csv_files = glob.glob('data/weather/*.csv')\n",
    "\n",
    "location_dict = {}\n",
    "\n",
    "for file in csv_files:\n",
    "    name = extract_location(file)\n",
    "    location_dict[name + '_df'] = file\n",
    "print(location_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weather(file_name, skip_rows):\n",
    "    '''A function to read in a weather csv file.'''\n",
    "       \n",
    "    file_path = 'data/weather/'\n",
    "\n",
    "    weather_df = pd.read_csv(file_path + file_name,\n",
    "                    skiprows = skip_rows,\n",
    "                    usecols= ['date', 'rain', 'temp', 'msl', 'wdsp', 'wddir'],\n",
    "                    na_values = ' ',\n",
    "                    index_col= 'date', \n",
    "                    parse_dates= ['date'], \n",
    "                    date_format = \"%d-%b-%Y %H:%M\"\n",
    "                    )\n",
    "    \n",
    "    weather_df = weather_df['2014': '2024']\n",
    "\n",
    "    return weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>msl</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wddir</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>989.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>989.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>988.8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>988.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>986.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rain  temp    msl  wdsp  wddir\n",
       "date                                               \n",
       "2014-01-01 00:00:00   0.0   4.0  989.6  10.0  180.0\n",
       "2014-01-01 01:00:00   0.0   3.8  989.3   9.0  180.0\n",
       "2014-01-01 02:00:00   0.0   3.6  988.8   9.0  150.0\n",
       "2014-01-01 03:00:00   0.0   2.9  988.0  11.0  170.0\n",
       "2014-01-01 04:00:00   0.0   4.0  986.5  10.0  150.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gurteen = load_weather('hly1475Gurteen.csv', 17)\n",
    "gurteen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>msl</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wddir</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01 00:00:00</th>\n",
       "      <td>0.2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>985.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 01:00:00</th>\n",
       "      <td>0.2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>985.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>984.6</td>\n",
       "      <td>21.0</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 03:00:00</th>\n",
       "      <td>0.5</td>\n",
       "      <td>8.3</td>\n",
       "      <td>983.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>982.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rain  temp    msl  wdsp  wddir\n",
       "date                                               \n",
       "2014-01-01 00:00:00   0.2   8.2  985.7  21.0  200.0\n",
       "2014-01-01 01:00:00   0.2   7.8  985.4  21.0  200.0\n",
       "2014-01-01 02:00:00   0.0   8.4  984.6  21.0  190.0\n",
       "2014-01-01 03:00:00   0.5   8.3  983.6  18.0  190.0\n",
       "2014-01-01 04:00:00   0.0   7.2  982.4  19.0  150.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macehead = load_weather('hly275MaceHead.csv', 17)\n",
    "macehead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mullingar = load_weather('hly875Mullingar.csv', 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "johnstown = load_weather('hly1775Johnstown.csv', 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "athenry = load_weather('hly1875Athenry.csv', 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "finner = load_weather('hly2075Finner.csv', 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refine dataframes to 2014 data onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_years(df):\n",
    "    df = df['2014': '2024']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "macehead = select_years(macehead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gurteen = select_years(gurteen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice merging dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rain_gur</th>\n",
       "      <th>temp_gur</th>\n",
       "      <th>msl_gur</th>\n",
       "      <th>wdsp_gur</th>\n",
       "      <th>wddir_gur</th>\n",
       "      <th>rain_mace</th>\n",
       "      <th>temp_mace</th>\n",
       "      <th>msl_mace</th>\n",
       "      <th>wdsp_mace</th>\n",
       "      <th>wddir_mace</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>989.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>985.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>989.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>985.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>988.8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>984.6</td>\n",
       "      <td>21.0</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>988.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.3</td>\n",
       "      <td>983.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>986.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>982.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rain_gur  temp_gur  msl_gur  wdsp_gur  wddir_gur  \\\n",
       "date                                                                    \n",
       "2014-01-01 00:00:00       0.0       4.0    989.6      10.0      180.0   \n",
       "2014-01-01 01:00:00       0.0       3.8    989.3       9.0      180.0   \n",
       "2014-01-01 02:00:00       0.0       3.6    988.8       9.0      150.0   \n",
       "2014-01-01 03:00:00       0.0       2.9    988.0      11.0      170.0   \n",
       "2014-01-01 04:00:00       0.0       4.0    986.5      10.0      150.0   \n",
       "\n",
       "                     rain_mace  temp_mace  msl_mace  wdsp_mace  wddir_mace  \n",
       "date                                                                        \n",
       "2014-01-01 00:00:00        0.2        8.2     985.7       21.0       200.0  \n",
       "2014-01-01 01:00:00        0.2        7.8     985.4       21.0       200.0  \n",
       "2014-01-01 02:00:00        0.0        8.4     984.6       21.0       190.0  \n",
       "2014-01-01 03:00:00        0.5        8.3     983.6       18.0       190.0  \n",
       "2014-01-01 04:00:00        0.0        7.2     982.4       19.0       150.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gurteen_macehead = gurteen.merge(macehead, on= 'date', suffixes= ['_gur', '_mace'])\n",
    "gurteen_macehead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = extract_location('hly275MaceHead.csv')\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = extract_location('hly1475Gurteen.csv')\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gurteen = load_weather('hly1475Gurteen.csv', 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regex the filename\n",
    " # Want df to have the station name in the name of the df\n",
    " #pattern = r'hly\\d{3,4}([A-Z][a-z]+).csv'\n",
    " #my_string = file_name\n",
    " #match = re.search(pattern, my_string)\n",
    " #name = match.group(1).lower()\n",
    " #name_df = f\"{name}_df\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(name_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to the file name to name the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df = name('hly275MaceHead.csv')\n",
    "\n",
    "df_name('hly875Mullingar.csv', 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mullingar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name('hly875Mullingar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame with name extracted from the csv file\n",
    "name_df = name('hly875Mullingar.csv')\n",
    "\n",
    "name_df = load_weather('hly875Mullingar.csv', 17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mullingar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_df = name('hly2375Belmullet.csv')\n",
    "name_df = load_weather('hly2375Belmullet.csv', 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belmullet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belmullet_df = pd.read_csv('data/weather/hly2375Belmullet.csv', \n",
    "                           skiprows = 23,\n",
    "                           usecols= ['date', 'rain', 'temp', 'msl', 'wdsp', 'wddir'],\n",
    "                           na_values = ' ',\n",
    "                           index_col= 'date', \n",
    "                           parse_dates= ['date'], \n",
    "                           date_format = \"%d-%b-%Y %H:%M\")\n",
    "\n",
    "belmullet_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows from 2014\n",
    "\n",
    "belmullet_df = belmullet_df.loc['2014' : '2024']\n",
    "\n",
    "belmullet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge weather dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Is Ireland getting windier? Use Dublin Airport data. Recorded from 1944. Also Valentia recorded from then too. Do Dublin first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dublin_df = pd.read_csv('data/weather/hly532DublinAirport.csv', \n",
    "                        skiprows = 23, \n",
    "                        na_values = ' ',\n",
    "                        index_col= 'date', \n",
    "                        parse_dates= ['date'], \n",
    "                        date_format = \"%d-%b-%Y %H:%M\")\n",
    "\n",
    "dublin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dublin_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dublin_df = dublin_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dublin_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dublin_monthly = dublin_df.resample('ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "\n",
    "dublin_yearly = dublin_df.resample('YE')\n",
    "\n",
    "\n",
    "dublin_df['wdsp'].resample('YE').mean().scatterplot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dublin_yearly['wdsp'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 11, 9\n",
    "\n",
    "decomposition = sm.tsa.seasonal_decompose(dublin_monthly['wdsp'].mean(), model= 'additive', period = 12)\n",
    "fig = decomposition.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose, STL , MSTL\n",
    "#from statsforecast import StatsForecast\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valentia_df = pd.read_csv('data/weather/hly2275Valentia.csv', \n",
    "                        skiprows = 23, \n",
    "                        na_values = ' ',\n",
    "                        index_col= 'date', \n",
    "                        parse_dates= ['date'], \n",
    "                        date_format = \"%d-%b-%Y %H:%M\")\n",
    "\n",
    "valentia_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15, 5))\n",
    "\n",
    "valentia_df['wdsp'].resample('YE').mean().plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valentia_monthly = valentia_df.resample('ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 11, 9\n",
    "\n",
    "decomposition = sm.tsa.seasonal_decompose(valentia_monthly['wdsp'].mean(), model= 'additive', period = 12)\n",
    "fig = decomposition.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very quick plot of electricity generation by year\n",
    "\n",
    "mean_wind_elect_year = electricity_df.resample('YE').mean()\n",
    "\n",
    "mean_wind_elect_year.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of the Analysis\n",
    "\n",
    "nice plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "some predictive analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "\n",
    "http://www.iwea.ie/technicalfaqs\n",
    "\n",
    "\n",
    "### Data Sets\n",
    "\n",
    "[GitHub Daniel Parke]https://github.com/Daniel-Parke/EirGrid_Data_Download/tree/main\n",
    "\n",
    "\n",
    "__Problems that arose__\n",
    "\n",
    "[Git LFS (large file storage)](https://git-lfs.com/). Some of the weather data filew were larger than GitHub's recommended maximum file size of 50.00 MB. Installed and used Git lfs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
